---
title: "P8105 Homework 5"
author: "Ruiyang Li"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

This is my solution to HW5.

```{r setup, include=FALSE}
library(tidyverse)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

Read in the data.

```{r homicide_df, collapse=TRUE, message=FALSE}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

A quick look at homicides. 

```{r aggregate_df, collapse=TRUE}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

A prop test for Baltimore, MD. 

```{r prop_test, collapse=TRUE}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Iterate. 

```{r results_df, collapse=TRUE}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

Plot the estimates and CIs for each city. 

```{r plot, collapse=TRUE}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



## Problem 2 

Create a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time. 

```{r lda_df, collapse=TRUE, message=FALSE}
lda_df = 
  tibble(file = list.files("lda_data")) %>% 
  mutate(
    path = str_c("lda_data/", file),
    data = map(.x = path, ~read_csv(.x))) %>% 
  unnest(data) %>% 
  select(-path) %>% 
  mutate(file = str_remove(file, ".csv")) %>% 
  separate(file, into = c("arm", "subj_id"), sep = "_") %>% 
  pivot_longer(
    week_1:week_8, 
    names_to = "week", 
    names_prefix = "week_", 
    values_to = "observation"
  ) %>% 
  mutate(week = as.numeric(week)) %>% 
  relocate(subj_id)

head(lda_df)
```

Make a spaghetti plot showing observations on each subject over time. 

```{r spaghetti_plot, collapse=TRUE}
lda_df %>% 
  group_by(subj_id, arm, week) %>% 
  ggplot(aes(x = week, y = observation, group = subj_id, color = subj_id)) +
  geom_point() + 
  geom_path() +
  facet_grid(~arm) +
  labs(title = "Observations on each subject over time", 
       x = "Week", 
       y = "Observations", 
       color = "Subject")
```

Comment on differences between groups: 

* At week 1, mean observations across subjects in both groups look similar, but those in the control group have less variation than those in the experiment group. 
* Over time, the observations in the control group seem to be constant and do not vary much within both group level and individual level. The mean of the observations in the control group at each week is around 1. 
* Over time, the observations in the experiment group seem to have an increasing trend within both group level and individual level. The mean of the observations in the experiment group starts at around 1 and gradually goes to around 5. 



## Problem 3

For μ = 0: 

```{r sim_0, collapse=TRUE}
set.seed(20201118)

n = 30
sigma = 5

sim_test = function(mu) {
    tibble(
      x = rnorm(n, mean = mu, sd = sigma)
    ) %>% 
    t.test() %>% 
    broom::tidy() %>% 
    select(estimate, p.value)
}

mu = 0 
sim_result = 
  rerun(5000, sim_test(mu)) %>% 
  bind_rows() %>% 
  janitor::clean_names()
```

For μ = 0, 1, 2, 3, 4, 5, 6: 

```{r sim_0_to_6, collapse=TRUE}
set.seed(20201118)

n = 30
sigma = 5

sim_test = function(mu) {
    tibble(
      x = rnorm(n, mean = mu, sd = sigma)
    ) %>% 
    t.test() %>% 
    broom::tidy() %>% 
    select(estimate, p.value)
}

sim_result = 
  tibble(true_mean = 0:6) %>% 
  mutate(
    output_lists = map(.x = true_mean, ~rerun(5000, sim_test(mu = .x))), 
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs) %>% 
  janitor::clean_names()
```

Make a plot showing the proportion of times the null was rejected (the power of the test). 

```{r plot_prop, collapse=TRUE}
sim_result %>% 
  mutate(
    true_mean = str_c("μ = ", true_mean), 
    true_mean = fct_inorder(true_mean)) %>% 
  group_by(true_mean) %>% 
  summarise(prop = sum(p_value < 0.05)/5000) %>% 
  ggplot(aes(y = prop, x = true_mean, fill = true_mean)) +
  geom_col(show.legend = FALSE) + 
  geom_text(aes(label = prop), vjust = -0.5) + 
  labs(
    y = "Proportion of times the null was rejected", 
    x = "True value of μ"
  )
```

The association between effect size and power: 

* From the above plot, we can see that the larger the effect size is the more power the test has. 

Make plots showing the true value of μ v.s. the average estimate of μ 1) in all samples and 2) only in samples for which the null was rejected. 

```{r plot_avg, collapse=TRUE}
plot_avg_all = 
  sim_result %>% 
  mutate(
    true_mean = str_c("μ = ", true_mean), 
    true_mean = fct_inorder(true_mean)) %>% 
  group_by(true_mean) %>% 
  summarise(avg = mean(estimate)) %>% 
  mutate(avg = round(avg, digits = 2)) %>% 
  ggplot(aes(y = avg, x = true_mean, color = true_mean)) +
  geom_point() + 
  geom_text(aes(label = avg), vjust = -0.5) + 
  theme(legend.position = "none") + 
  labs(
    y = "Average estimate of μ", 
    x = "True value of μ", 
    title = "All samples"
  )

plot_avg_rejected = 
  sim_result %>% 
  filter(p_value < 0.05) %>% 
  mutate(
    true_mean = str_c("μ = ", true_mean), 
    true_mean = fct_inorder(true_mean)) %>% 
  group_by(true_mean) %>% 
  summarise(avg = mean(estimate)) %>% 
  mutate(avg = round(avg, digits = 2)) %>% 
  ggplot(aes(y = avg, x = true_mean, color = true_mean)) +
  geom_point(size = 2) + 
  geom_text(aes(label = avg), vjust = -0.5) + 
  theme(legend.position = "none") + 
  labs(
    y = "Average estimate of μ", 
    x = "True value of μ", 
    title = "Samples for which the null was rejected "
  )

plot_avg_all + plot_avg_rejected
```

* The sample average of μ estimates across tests for which the null is rejected is not approximately equal to the true value of μ when μ is close to 0 (e.g. 0, 1, 2, maybe 3), but it is approximately equal to the true μ when μ is more away from 0 (e.g. 5 and 6 in our case). 
* This is because we reject the null hypothesis that the true μ is 0 if it is not likely that the estimated μ is different from 0 by chance only (i.e., the estimated μ is statistically significantly different from 0). So, when the true μ is close to 0, each sample for which the null hypothesis is rejected has its estimated μ different from 0, and as a result, the average estimate of μ is different from its true μ. However, when the true μ is much away from 0, we expect to see that each sample for which the null hypothesis is rejected has its estimated μ different from 0, and as a result, we do not expect to see the average estimate of μ is much different from its true μ.

